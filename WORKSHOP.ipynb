{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e1b642-20bd-4ba4-b19f-9a61b67f0eec",
   "metadata": {},
   "source": [
    "# Taller: Ingenería de Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2aed1-811d-4f71-8373-a907036bfc1e",
   "metadata": {},
   "source": [
    "# Parte 1. Pautas para hacer prompts\n",
    "\n",
    "A lo largo de este taller, utilizaremos la version del modelo de OpenAI `gpt-3.5-turbo` y chat completions endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f006344-29a0-442f-941f-776e1a590564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue la clave API y la biblioteca OpenAI\n",
    "import openai\n",
    "openai.api_key = \"sk-[you-key]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7b6c4a-2cee-4243-a774-5878a6110e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta función auxiliar facilitará el uso de prompts y nos ayudará a visualizar los resultados\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581ca54-b806-4a98-afe9-9ae93a5239ca",
   "metadata": {},
   "source": [
    "**1. Zero-shot (Prompt sin entrenamiento previo (sin ejemplos))**\n",
    "\n",
    "- Usa delimitadores para indicar distintas partes en el texto de entrada\n",
    "- Delimiadores pueden ser: ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188a2fa-aeec-4dd7-82d5-0adeb10b7f78",
   "metadata": {},
   "source": [
    "Zero-shot prompting es la forma más básica de hacer prompts. Simplemente muestra al modelo un mensaje sin ejemplos y le pide que genere una respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e45222e-0767-4436-9a59-427102989712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Vale la pena\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Determine si el tono del texto es positivo o negativo. Formato de respuesta es una sola palabra.\n",
    "Texto:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e311c54-64e0-47e8-9aef-a5a179185e36",
   "metadata": {},
   "source": [
    "**2. Few-shot\t(Prompt con ejemplos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ac6e2-4635-4b98-ae18-7480a09f6725",
   "metadata": {},
   "source": [
    "Few-shot prompt es proporcionar al LLM ejemplos de cómo completar la tarea. De este modo, el modelo puede emular la finalización exitosa de una tarea similar, en lugar de descubrir cómo hacerla desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd31ddf2-e4eb-4454-8bfe-791e7de3c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negativo\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "¡No funciona!\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Gran producto, 10/10: positivo\n",
    "No funcionó muy bien: negativo\n",
    "Súper útil, vale la pena: positivo.\n",
    "Texto:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9fba9-1162-4f96-a315-6d9b38eb8e96",
   "metadata": {},
   "source": [
    "**3. CoT – Chain-of-Thought (Prompt cadena de pensamientos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2552e7-9194-4aec-b3ad-e710b1c305de",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "\n",
    "Texto:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865b53b-81cd-4733-a422-6622685481bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd2d2f79-1363-49d7-8c5d-82e3bc99bb4f",
   "metadata": {},
   "source": [
    "## Limitaciones del modelo: Alucinaciones\n",
    "- Boie es una companía real, el producto no existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee128f-8c63-4e0f-803e-cfa0a8677256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Háblame del cepillo de dientes inteligente AeroGlide UltraSlim de Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637e740-9289-4f38-b4bc-03b0c1fa89c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Háblame del cepillo de dientes inteligente AeroGlide UltraSlim de Boie si tal producto existe en el mercado\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1e8c8-fea4-49a7-bc83-a524b6e12ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Primero investiga si la empresa Boie tiene el cepillo de dientes inteligente AeroGlide UltraSlim. \n",
    "Si la respuesta es no, responde con la frase \"el producto no existe\", si la respuesta es positiva, \n",
    "háblame del cepillo de dientes inteligente AeroGlide UltraSlim de Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdcb22-be59-4cb4-adcb-141848d6dbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b972e5db-3459-4ef7-9ef9-1a8bb0b015ed",
   "metadata": {},
   "source": [
    "# Parte 2. Transformaciones aplicadas al texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f1ec0-0fd0-4aff-a1ac-76c39dd6b635",
   "metadata": {},
   "source": [
    "## Resumen del texto (Summarizing)\n",
    "Vamos a resumir unas reseñas enfocandosé en diferentes detalles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425ff14-f1bd-4fbd-bd07-a064ea6e1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseña de un peluche\n",
    "prod_review = \"\"\"\n",
    "Compré este peluche de panda para el cumpleaños de mi hija, \\\n",
    "a quien le encanta y lo lleva a todas partes. Es suave y \\ \n",
    "súper lindo, y su cara tiene una mirada amigable. Sin embargo, es \\ \n",
    "un poco pequeño para lo que pagué. Creo que \\ \n",
    "podría haber otras opciones más grandes por el \\ \n",
    "mismo precio. Llegó un día antes de lo esperado, \\ \n",
    "así que pude jugar con él antes de dárselo a ella. \\ \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6469d-7ef2-4e7a-94b9-c3fbe6ba163a",
   "metadata": {},
   "source": [
    "**1. Resumen con límite de palabras/oraciones/caracteres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7810d9-856c-424e-9def-7b8b9e23765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Su tarea es generar un breve resumen de una reseña del producto \\\n",
    "de un sitio de comercio electrónico.\n",
    "\n",
    "Resuma la reseña a continuación, delimitada por triples \\\n",
    "comillas, en un máximo de 30 palabras.\n",
    "\n",
    "Reseña: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281dfcf-7405-4260-b84c-5d3ec9fe5ba3",
   "metadata": {},
   "source": [
    "**2. Resumen enfocado en un aspecto específico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e5185-9269-4eef-b3fc-44d3280e495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intento 1\n",
    "prompt = f\"\"\"\n",
    "Su tarea es generar un breve resumen de una reseña \\\n",
    "de producto de un sitio de comercio electrónico para \\\n",
    "enviar comentarios al departamento de envíos. \\\n",
    "\n",
    "Resuma la reseña a continuación, delimitada por \\\n",
    "triples comillas, en un máximo de 30 palabras, \\\n",
    "y centrándose en cualquier aspecto que mencione \\\n",
    "el envío y la entrega del producto.\n",
    "\n",
    "Reseña: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17820ea-8e3e-4f13-92ed-97f4a3ce1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intento 2\n",
    "prompt = f\"\"\"\n",
    "Su tarea es generar un breve resumen de una \\\n",
    "reseña de producto de un sitio de comercio \\\n",
    "electrónico para enviar comentarios al departamento \\\n",
    "de precios, responsable de determinar el precio del producto.\n",
    "\n",
    "Resuma la reseña a continuación, delimitada por \\\n",
    "triples comillas invertidas, en un máximo de 30 \\\n",
    "palabras, y centrándose en cualquier aspecto que \\\n",
    "sea relevante para el precio y el valor percibido.\n",
    "\n",
    "Reseña: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78eacc8-0f3a-4b97-b2df-72079384caf3",
   "metadata": {},
   "source": [
    "**Comentario**\n",
    "- Estos resumenes ademas de la información solicitada, tb incluyen detalles que no le pedimos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f7e75-9af4-4dc5-86c6-4a923444fb70",
   "metadata": {},
   "source": [
    "**3. Intenta \"extraer\" (extract) en vez de \"resumir\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fb56a-ea16-45dd-8839-9d6f3894e9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Su tarea es extraer información relevante de una \\\n",
    "reseña de producto para enviar comentarios al \\\n",
    "departamento de envío.\n",
    "\n",
    "De la reseña a continuación, delimitada por \\\n",
    "triples comillas, extraiga solo la información \\\n",
    "relevante para el envío y la entrega. Omite \\\n",
    "todos detalles que no describen envío o entrega. \\\n",
    "Límite de 30 palabras.\n",
    "\n",
    "Reseña: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de25805-1435-4533-94ab-74f7dc403211",
   "metadata": {},
   "source": [
    "**4. Resume varias reseñas**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d0056-77eb-4758-9b77-5fd4ba557b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_1 = prod_review \n",
    "\n",
    "# reseña de una silla\n",
    "review_2 = \"\"\"\n",
    "Para el precio que la compre 98€ no está nada mal, por las \\\n",
    "tonterias que tiene de posapies, vibracion de lumbar etc, \\\n",
    "pero siendo sinceros, por 144 es un atraco, no tiene apenas \\\n",
    "comodidad, es muy estrecha, osea que si eres ancho lo vas a \\\n",
    "pasar mal, como midas mas de 1,70 y poco ya te pasas de \\\n",
    "altura y los cojines apenas te sirven, nada mas te sientas \\\n",
    "notas que a las ruedas le cuesta rodar, y si tienes gato \\\n",
    "preparate porque de tres rascadas te lo rompe. Eso si, el \\\n",
    "montaje muy sencillo y esteticamente pues puede ser bonita, \\\n",
    "pero vengo de tener una silla muy comoda y esta me ha \\\n",
    "decepcionado en cierto modo. No la recomendaría por el \\\n",
    "precio que tiene\n",
    "\"\"\"\n",
    "\n",
    "# reseña de una lámpara\n",
    "review_3 = \"\"\"\n",
    "Estaba encantado con la lámpara hasta que se ha roto, \\\n",
    "¿motivo?: desconocido. Su función es estar encima de \\\n",
    "la mesita de noche, usar el cargador casi a diario y \\\n",
    "encenderla de higos a brevas. No sé si son 5, 6 o 7 meses \\\n",
    "desde la compra, pero vamos... que se entiende una lampara \\\n",
    "si no le metes un meneo y la rompes debe de durar toda la \\\n",
    "vida... no meses como ha sido el caso, y ahora que hago \\\n",
    "con una lámpara rota y la otra no??? Pues envainarmela, \\\n",
    "coger otras 2 lamparas de noche y enviar una opinión lo \\\n",
    "más sincera posible: no compreis este artículo, os \\\n",
    "defraudará como a mí \n",
    "\"\"\"\n",
    "\n",
    "# reseña de un cepillo de dientes\n",
    "review_4 = \"\"\"\n",
    "Llevo más de 2 meses usándolos, anteriormente utilizaba \\\n",
    "uno eléctrico de marca muy popular y no he vuelto a usarlo \\\n",
    "pues estos dejan los dientes igual de limpios o mejor y \\\n",
    "encima no dañan absolutamente nada las encías. Es increíble \\\n",
    "el resultado, a pesar de que el tacto es suave. Los usamos \\\n",
    "ya toda la familia. A mi hermano le quitan hasta las manchas \\\n",
    "del tabaco. He comprado el de viaje pues estoy encantada. \\\n",
    "Tengo 1 implante y elimina genial cualquier resto de comida \\\n",
    "que pueda quedarse. Desde ahora es mi cepillo habitual. Si \\\n",
    "lo prueban se sorprenderán. \n",
    "100% RECOMENDABLE\n",
    "\"\"\"\n",
    "\n",
    "reviews = [review_1, review_2, review_3, review_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa1d5f-7a50-41fb-8815-8e9a63c23dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    prompt = f\"\"\"\n",
    "    Su tarea es generar un breve resumen de una reseña de producto de un sitio de comercio electrónico. \n",
    "\n",
    "    Resuma la reseña a continuación, delimitada por triples comillas en un máximo de 20 palabras.\n",
    "    \n",
    "    Reseña: ```{reviews[i]}```\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    print(i, response, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b230a1-f204-4159-ac26-a979866d47e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4d78c1d-52ff-4393-ae1d-7c8874d3abde",
   "metadata": {},
   "source": [
    "## Inferencia (Inferring) \n",
    "Vamos a inferir opiniones y temas a partir de reseñas de productos y artículos de noticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9584978-07b5-4693-bcb5-9cbd1a9d14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Estaba encantado con la lámpara de la marca Tomshine hasta que se ha roto, \\\n",
    "¿motivo?: desconocido. Su función es estar encima de \\\n",
    "la mesita de noche, usar el cargador casi a diario y \\\n",
    "encenderla de higos a brevas. No sé si son 5, 6 o 7 meses \\\n",
    "desde la compra, pero vamos... que se entiende una lampara \\\n",
    "si no le metes un meneo y la rompes debe de durar toda la \\\n",
    "vida... no meses como ha sido el caso, y ahora que hago \\\n",
    "con una lámpara rota y la otra no??? Pues envainarmela, \\\n",
    "coger otras 2 lamparas de noche y enviar una opinión lo \\\n",
    "más sincera posible: no compreis este artículo, os \\\n",
    "defraudará como a mí \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f27ae-bd37-429d-8d88-891259f81c57",
   "metadata": {},
   "source": [
    "**1. Análisis de sentimiento (positivo/negativo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7b2af-1faa-449c-bf93-4fe536ab40e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "¿Cuál es el sentimiento del texto de la reseña del producto, positivo o negativo?\n",
    "\n",
    "Texto de la reseña: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cf380-5b03-414b-b68f-e3494e008864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dando forma a la respuesta según tus necesidades\n",
    "prompt = f\"\"\"\n",
    "¿Cuál es el sentimiento del texto de la reseña del producto?\n",
    "\n",
    "Da tu respuesta en una sola palabra, ya sea \"positivo\" o \"negativo\".\n",
    "\n",
    "Texto de la reseña: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4b05b-19b3-4e62-9abc-c1c62fdba192",
   "metadata": {},
   "source": [
    "**2. Identifica tipos de emociones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599df62-d7f5-4f7a-b174-9944295b92b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica emociones del texto\n",
    "prompt = f\"\"\"\n",
    "Identifique una lista de emociones que expresa el autor \\\n",
    "de la siguiente reseña. No incluya más de cinco elementos \\\n",
    "en la lista. Formatee su respuesta como una lista de \\\n",
    "palabras en minúscula separadas por comas.\n",
    "\n",
    "Texto de la reseña: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde6399-91ab-42ce-a934-828269b647eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta sobre una emoción en particular (Ira)\n",
    "prompt = f\"\"\"\n",
    "¿El autor de la siguiente reseña está expresando ira? \\\n",
    "La reseña está delimitada con triples comillas. \n",
    "Dé su respuesta como sí o no.\n",
    "\n",
    "Texto de la reseña: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c623f-a47d-4cc4-b1dc-dc4a16a584cb",
   "metadata": {},
   "source": [
    "**3. Extraiga el nombre del producto y de la marca de las reseñas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f7e28-47b9-4475-ae6f-2aa4c054184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique los siguientes elementos del texto de la reseña:\n",
    "- Artículo comprado por el cliente\n",
    "- Empresa que fabricó el artículo.\n",
    "\n",
    "La reseña está delimitada con triples comillas. \\\n",
    "Formatee su respuesta como un objeto JSON con \"Artículo\" y \"Marca\" como claves. \\\n",
    "Si la información no está presente, utilice \"desconocido\" como valor. \\\n",
    "Haga su respuesta lo más breve posible.\n",
    "  \n",
    "Texto de la reseña: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acdd08-316b-4278-ba02-d3f0142554bf",
   "metadata": {},
   "source": [
    "**4. Realizar varias tareas de forma simultánea**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc12e52-89c2-4ad9-9324-fe827b6a80aa",
   "metadata": {},
   "source": [
    "Siempre que estructuras tu prompt de forma correcta y eficiente, puedes hacerla procesar varias tareas al mismo tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762deae-073b-47b7-9094-54c8281bdacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique los siguientes elementos del texto de la reseña:\n",
    "- Sentimiento (positivo o negativo)\n",
    "- ¿El cliente expresa ira? (verdadero o falso)\n",
    "- Artículo comprado por el cliente\n",
    "- Empresa que fabricó el artículo.\n",
    "\n",
    "La reseña está delimitada con triples comillas. Formatee su \\\n",
    "respuesta como un objeto JSON con claves \"Sentimiento\", \\\n",
    "\"Ira\", \"Artículo\" y \"Marca\".\n",
    "Si la información no está presente, utilice \"desconocido\" \\\n",
    "como valor.\n",
    "Haga su respuesta lo más breve posible.\n",
    "Formatee el valor de Ira como booleano.\n",
    "\n",
    "Texto de la reseña: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793fb57a-f675-4078-bbd1-857a05e3d7e0",
   "metadata": {},
   "source": [
    "**5. Identificar temas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec9c7a-4474-40c4-a1da-952b766f6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "La misión DART (Double Asteroid Redirection Test, por sus \\\n",
    "siglas en inglés) es la primera prueba de defensa planetaria \\\n",
    "que evita los posibles impactos de asteroides contra la \\\n",
    "Tierra. En 2021, se lanzó al espacio y, en septiembre del año \\\n",
    "pasado, se estrelló a toda velocidad contra el asteroide Dimorphos \\\n",
    "para desviar su trayectoria –lo que supuso el primer ensayo de la \\\n",
    "humanidad para defender a la Tierra de la colisión de futuros \\\n",
    "objetos espaciales–.\n",
    "\n",
    "Fue la primera vez en la historia que se intentó cambiar la trayectoria \\\n",
    "de un cuerpo celeste, en un intento de proteger a la Tierra de \\\n",
    "meteoritos similares al que hace 66 millones de años provocó la \\\n",
    "extinción de los dinosaurios. Pero a día de hoy, los científicos han \\\n",
    "empezado a estudiar las eyecciones, las rocas y los numerosos \\\n",
    "fragmentos más pequeños que desprendió el impacto de la misión DART.\n",
    "\n",
    "La nave DART de la NASA colisionó contra el asteroide Dimorphos y \\\n",
    "su órbita se ha desviado en 33 minutos aproximadamente.La nave DART \\\n",
    "de la NASA colisionó contra el asteroide Dimorphos en septiembre \\\n",
    "del año pasado.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc674d6-4682-440d-b9dc-be4202c7c8a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'story' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b2f8e132ef09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mFormatee\u001b[0m \u001b[0msu\u001b[0m \u001b[0mrespuesta\u001b[0m \u001b[0mcomo\u001b[0m \u001b[0muna\u001b[0m \u001b[0mlista\u001b[0m \u001b[0mde\u001b[0m \u001b[0melementos\u001b[0m \u001b[0mseparados\u001b[0m \u001b[0mpor\u001b[0m \u001b[0mcomas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mTexto\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'''{story}'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \"\"\"\n\u001b[0;32m     12\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'story' is not defined"
     ]
    }
   ],
   "source": [
    "# Saca 5 temas\n",
    "prompt = f\"\"\"\n",
    "Saca cinco temas que se están discutiendo en el \\\n",
    "siguiente texto, el cual está delimitado por triples comillas.\n",
    "\n",
    "Haga que cada elemento tenga una o dos palabras.\n",
    "\n",
    "Formatee su respuesta como una lista de elementos separados por comas.\n",
    "\n",
    "Texto: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf21b7-41e5-4390-b588-4690b069c0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1a81fb9-b3e6-4499-b09e-18671d279869",
   "metadata": {},
   "source": [
    "## Transformación del texto\n",
    "\n",
    "Uso de ChatGPT para tareas de transformación de texto, como traducción, revisión ortográfica y gramatical, tono y conversión de formato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86377393-df1c-4513-b96d-c6a41b83f7fe",
   "metadata": {},
   "source": [
    "**1. Traducción**\n",
    "\n",
    "ChatGPT está entrenado con fuentes en muchos idiomas. Esto le da al modelo la capacidad de realizar traducciones. A continuación se muestran algunos ejemplos de cómo utilizar esta capacidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f41fde-d0fe-43b7-a23a-bbc2dc8f7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traducir de un idioma al otro\n",
    "prompt = f\"\"\"\n",
    "Traduzca el texto delimitado por triples comillas de inglés al español: \\\n",
    "```Hi, I would like to order a blender```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996d4a6-ac76-4fc7-a5c2-e55ff130daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir idioma del texto\n",
    "prompt = f\"\"\"\n",
    "Dime que idioma es este: \n",
    "```Combien coûte le lampadaire?```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21991d86-fe64-409f-83ba-08d50b989aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traducir de un idioma a varios\n",
    "prompt = f\"\"\"\n",
    "Traduzca el texto siguiente al francés y español:\n",
    "```I want to order a basketball```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f87caa-aab7-4e62-96c9-e2f975da1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduzca el siguiente texto al español tanto en su forma formal como informal.\n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a35ff1-229e-4d9d-900f-35748e8d0c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85fb30df-3f04-4d4a-82af-d3400a72cba5",
   "metadata": {},
   "source": [
    "**2. Transformación de tono**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57988025-4563-4a5e-a8c9-347e2fb2f04d",
   "metadata": {},
   "source": [
    "ChatGPT puede producir diferentes tonos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c81123-5269-41e1-aa84-f34a21a8f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduce lo siguiente de la jerga a una carta comercial:\n",
    "\"Amigo, soy Juan, mira las especificaciones de esta lámpara\".\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3525b44-33c1-4763-bd3f-9863b11bf6de",
   "metadata": {},
   "source": [
    "**3. Conversión de formato**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b60a4d-d8d0-48e5-a42d-02b4ef6238ce",
   "metadata": {},
   "source": [
    "ChatGPT puede traducir entre formatos. El prompt debe describir los formatos de entrada y salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80bedd-8ed5-486a-bfe3-9a7496718512",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = { \"empleados del resturante\" :[ \n",
    "    {\"nombre\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
    "    {\"nombre\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"nombre\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Traduzca el siguiente diccionario de Python de JSON a \\\n",
    "una tabla HTML con encabezados de columna y título: {data_json}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233139c1-f8f4-4ee3-9676-47a1fe442657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52affd4-f153-4695-9d1e-b25d59ebe929",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [ \n",
    "  \"La niña con los cachorros blanco y negro tiene un pelota.\",  # una pelota\n",
    "  \"Yolanda tiene una libreta.\", # ok\n",
    "  \"Va aser un día largo. ¿El auto necesita un cambio de aceite?\",  # a ser\n",
    "  \"De ahí va mi libertad. Van a trae las maletas.\",  # las maletas\n",
    "  \"Vas a necesitar tu cuaderno\",  # ok\n",
    "  \"Ese medicamento efecta mi capacidad para dormir. ¿Has oído hablar del efecto mariposa?\", # afecta\n",
    "  \"Esta frase es para comprobar la capacidad de corregir ortografia del chatGPT.\"  # spelling\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"   \n",
    "    Revisa y corrige el siguiente texto y reescribe la versión corregida. \n",
    "    Si no encuentra errores, simplemente diga \"No hay errores\". No utilices \n",
    "    puntuación alrededor del texto:\n",
    "    ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa357399-80fe-4265-954b-04e104b9fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "Le compré esto ami hija para su cumpleaños por que \\\n",
    "sigue sacando el mio de mi habitación. Sí, a los \\\n",
    "adultos también les gustan los pandas. Lo lleva a \\\n",
    "todas parte y era súper suave y lindo. Un de las \\\n",
    "orejas es un poco más baja que otra y no creio que \\\n",
    "haya sido diseñada para ser asimetrica. Aunque es un \\\n",
    "poco pequeño para lo que pagué por él. Creo que puede \\\n",
    "haber otras opciones mas grandes por el mismo precio. \\\n",
    "Llego un día antes de lo esperado, así que pude jugar \\\n",
    "con él antes de dárselo a mi hija.\n",
    "\"\"\"\n",
    "prompt = f\"revisa y corrige esta reseña: ```{text}```\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e617bd-8ace-4bb5-b310-26ab34d7686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redlines import Redlines\n",
    "\n",
    "diff = Redlines(text,response)\n",
    "display(Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0947a18-4e2c-4b69-8e45-bbdbd40089d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
